# Langchain RAG using Async FastAPI and Qdrant ğŸš€

A modern document Question-Answering system built with Langchain, AsyncIO, FastAPI, and Qdrant vector store.

## ğŸŒŸ Features

- ğŸ“š PDF Document Upload and Processing
- ğŸ” Advanced RAG (Retrieval Augmented Generation)
- âš¡ Async API Implementation with FastAPI
- ğŸ—ƒï¸ Qdrant Vector Store Integration
- ğŸ’¾ Caching System for Improved Performance
- ğŸ“ Conversation History Tracking
- ğŸ”„ Automatic Query Refinement
- ğŸ“Š Debug Information and Performance Metrics

## ğŸ› ï¸ Tech Stack

- FastAPI
- Langchain
- Qdrant
- AsyncIO
- Python 3.11+
- SQLite (for caching and chat logs)

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11 or higher
- pip package manager

### ğŸ”§ Installation

1. Clone the repository:

```bash
git clone https://github.com/rajmansuriya21/Langchain-RAG-using-Async-Fastapi-and-Qdrant.git
cd Langchain-RAG-using-Async-Fastapi-and-Qdrant
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run the FastAPI server:

```bash
uvicorn api:app --host 0.0.0.0 --port 8001 --reload
```

## ğŸ“š API Endpoints

### Upload Document

```http
POST /upload-knowledge
```

### Chat Interface

```http
POST /chat
```

Request body:

```json
{
  "username": "string",
  "query": "string",
  "session_id": "string",
  "no_of_chunks": 3
}
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ api.py              # FastAPI application and endpoints
â”œâ”€â”€ services/          # Core services
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ pydantic_models.py
â”œâ”€â”€ utils/             # Utility functions
â”‚   â”œâ”€â”€ cache_utils.py
â”‚   â”œâ”€â”€ db_utils.py
â”‚   â”œâ”€â”€ langchain_utils.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ qdrant_utils.py
â”‚   â””â”€â”€ retry_utils.py
â””â”€â”€ uploads/           # Document storage
```

## ğŸŒŸ Features in Detail

1. **Document Processing**

   - PDF document uploading and processing
   - Text chunk extraction and vectorization

2. **RAG Implementation**

   - Advanced retrieval using Qdrant vector store
   - Context-aware response generation
   - Query refinement for better results

3. **Performance Optimization**

   - Caching system for faster responses
   - Async implementation for better scalability
   - Configurable chunk sizes for retrieval

4. **Monitoring and Debugging**
   - Detailed response metrics
   - Token usage tracking
   - Processing time information
   - Debug context information

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## âœ¨ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ‘¥ Author

- Raj Mansuriya ([@rajmansuriya21](https://github.com/rajmansuriya21))

---

â­ If you find this project helpful, please give it a star!
